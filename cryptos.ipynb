{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse Crypto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0880ef4b1cd74b0992e135e638e6a4a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Symbole:', layout=Layout(width='150px'), options=('BTCUSDT', 'ETHUSDT'), ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d75808b973b04455a119354e0e8d8b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "import warnings\n",
    "from ipywidgets import FloatProgress, HTML, VBox, IntSlider, Button, HBox, Label, Output\n",
    "from ipywidgets import Dropdown, DatePicker\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Widget pour s√©lectionner le symbole\n",
    "symbol_dropdown = Dropdown(\n",
    "    options=['BTCUSDT', 'ETHUSDT'],\n",
    "    value='BTCUSDT',\n",
    "    description='Symbole:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout={'width': '150px'}\n",
    ")\n",
    "duree_slider = IntSlider(\n",
    "    value=365,\n",
    "    min=1,\n",
    "    max=730,\n",
    "    step=1,\n",
    "    description='Dur√©e (jours):',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout={'width': '400px'}\n",
    ")\n",
    "\n",
    "# Widget pour s√©lectionner l'intervalle\n",
    "from ipywidgets import Dropdown\n",
    "interval_dropdown = Dropdown(\n",
    "    options=['1m', '5m', '15m', '30m', '1h', '2h', '4h', '6h', '8h', '12h', '1d', '3d', '1w', '1M'],\n",
    "    value='1h',\n",
    "    description='Intervalle:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout={'width': '200px'}\n",
    ")\n",
    "\n",
    "# Widget pour s√©lectionner la date de fin\n",
    "end_date_picker = DatePicker(\n",
    "    description='Date de fin:',\n",
    "    value=datetime.now().date(),\n",
    "    style={'description_width': 'initial'},\n",
    "    layout={'width': '200px'}\n",
    ")\n",
    "\n",
    "# Bouton pour lancer le t√©l√©chargement\n",
    "download_button = Button(\n",
    "    description='T√©l√©charger les donn√©es',\n",
    "    button_style='primary',\n",
    "    tooltip='Cliquez pour lancer le t√©l√©chargement des donn√©es Binance Vision'\n",
    ")\n",
    "\n",
    "# Bouton pour lancer la visualisation\n",
    "visualize_button = Button(\n",
    "    description='Visualiser les donn√©es',\n",
    "    button_style='success',\n",
    "    tooltip='Cliquez pour afficher les graphiques d\\'analyse (n√©cessite des donn√©es t√©l√©charg√©es)',\n",
    "    disabled=True  # D√©sactiv√© par d√©faut\n",
    ")\n",
    "\n",
    "# Zone de sortie pour les messages\n",
    "output_area = Output()\n",
    "\n",
    "# Variables globales (seront mises √† jour par les widgets)\n",
    "DUREE_JOURS = duree_slider.value\n",
    "INTERVAL = interval_dropdown.value\n",
    "SYMBOL = symbol_dropdown.value\n",
    "END_DATE = end_date_picker.value.strftime('%Y-%m-%d') if end_date_picker.value else datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "# Initialiser les variables globales pour √©viter les erreurs\n",
    "btc_data = []\n",
    "df_btc = pd.DataFrame()\n",
    "\n",
    "# Fonction callback pour le bouton de t√©l√©chargement\n",
    "def on_download_click(b):\n",
    "    global DUREE_JOURS, INTERVAL, btc_data, df_btc\n",
    "    \n",
    "    with output_area:\n",
    "        clear_output(wait=True)\n",
    "        print(\"=== LANCEMENT DU T√âL√âCHARGEMENT ===\")\n",
    "        print(f\"Configuration:\")\n",
    "        print(f\"- Symbole: {symbol_dropdown.value}\")\n",
    "        print(f\"- Dur√©e d'analyse: {duree_slider.value} jours\")\n",
    "        print(f\"- Intervalle: {interval_dropdown.value}\")\n",
    "        print(f\"- Date de fin: {end_date_picker.value.strftime('%Y-%m-%d') if end_date_picker.value else 'Non d√©finie'}\")\n",
    "        print(f\"- Source: Binance Vision (donn√©es historiques)\")\n",
    "        print()\n",
    "        \n",
    "        # Mettre √† jour les variables globales\n",
    "        DUREE_JOURS = duree_slider.value\n",
    "        INTERVAL = interval_dropdown.value\n",
    "        SYMBOL = symbol_dropdown.value\n",
    "        END_DATE = end_date_picker.value.strftime('%Y-%m-%d') if end_date_picker.value else datetime.now().strftime('%Y-%m-%d')\n",
    "        \n",
    "        # Lancer le t√©l√©chargement\n",
    "        btc_data = download_binance_vision_data(SYMBOL, INTERVAL, DUREE_JOURS)\n",
    "        \n",
    "        # Cr√©er le DataFrame\n",
    "        df_btc = create_dataframe(btc_data, SYMBOL)\n",
    "        \n",
    "        if len(df_btc) > 0:\n",
    "            print(\"\\n‚úÖ T√©l√©chargement termin√© avec succ√®s!\")\n",
    "            print(f\"Donn√©es r√©cup√©r√©es: {len(df_btc)} p√©riodes\")\n",
    "            print(f\"P√©riode: {df_btc.index.min()} √† {df_btc.index.max()}\")\n",
    "            # Activer le bouton de visualisation\n",
    "            visualize_button.disabled = False\n",
    "            print(\"\\nüéØ Vous pouvez maintenant cliquer sur 'Visualiser les donn√©es' pour afficher les graphiques.\")\n",
    "        else:\n",
    "            print(\"\\n‚ùå √âchec du t√©l√©chargement - Aucune donn√©e r√©cup√©r√©e\")\n",
    "            visualize_button.disabled = True\n",
    "\n",
    "# Fonction callback pour le bouton de visualisation\n",
    "def on_visualize_click(b):\n",
    "    global df_btc\n",
    "    \n",
    "    with output_area:\n",
    "        clear_output(wait=True)\n",
    "        print(\"=== G√âN√âRATION DES VISUALISATIONS ===\")\n",
    "        print(f\"Analyse de {len(df_btc)} p√©riodes de {symbol_dropdown.value}\")\n",
    "        print(f\"P√©riode: {df_btc.index.min()} √† {df_btc.index.max()}\")\n",
    "        print()\n",
    "        \n",
    "        # Ex√©cuter la visualisation\n",
    "        create_visualization()\n",
    "\n",
    "# Fonction pour cr√©er les visualisations\n",
    "def create_visualization():\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "    import numpy as np\n",
    "    import pywt  # PyWavelets pour l'analyse par ondelettes\n",
    "\n",
    "    # Param√®tres configurables\n",
    "    MA_PERIOD = 24  # P√©riode de la moyenne mobile\n",
    "    TOP_FREQUENCIES = 200  # Nombre de pics dominants √† garder pour la reconstruction filtr√©e\n",
    "\n",
    "    if len(df_btc) > 0:\n",
    "        # Calculer la moyenne mobile sur les MA_PERIOD derni√®res p√©riodes\n",
    "        df_btc[f'ma_{MA_PERIOD}'] = df_btc['close'].rolling(window=MA_PERIOD).mean()\n",
    "        # D√©calage vers la gauche pour aligner (la fin des donn√©es n'est pas importante)\n",
    "        decalage = MA_PERIOD // 2\n",
    "        df_btc[f'ma_{MA_PERIOD}_shifted'] = df_btc[f'ma_{MA_PERIOD}'].shift(-decalage)\n",
    "\n",
    "        # Calculer la diff√©rence entre close et la MA d√©cal√©e\n",
    "        df_btc['diff_close_ma'] = df_btc['close'] - df_btc[f'ma_{MA_PERIOD}_shifted']\n",
    "\n",
    "        # S√©rie de diff√©rences (sans NaN)\n",
    "        diff_series = df_btc['diff_close_ma'].dropna()\n",
    "        difference_values = diff_series.values\n",
    "\n",
    "        # --- Cr√©ation de quatre subplots empil√©s (prix+volume, diff temporelle, ondelettes, spectre) ---\n",
    "        # Le premier subplot aura un axe Y secondaire pour le volume\n",
    "        fig = make_subplots(\n",
    "            rows=4,\n",
    "            cols=1,\n",
    "            shared_xaxes=False,  # On va g√©rer manuellement la synchronisation\n",
    "            vertical_spacing=0.05,\n",
    "            specs=[[{\"secondary_y\": True}],   # Axe Y secondaire pour le volume\n",
    "                   [{\"secondary_y\": False}], \n",
    "                   [{\"secondary_y\": False}],  # Ondelettes\n",
    "                   [{\"secondary_y\": False}]],\n",
    "            subplot_titles=('Prix, Moyenne Mobile & Volume', 'Diff√©rence (Close - MA)', 'Ondelettes sur Diff√©rence - Basses Fr√©quences', 'Spectre FFT (Fr√©quences)')\n",
    "        )\n",
    "\n",
    "        # Prix + MA sur la premi√®re rang√©e (row=1) - axe Y primaire\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=df_btc.index, y=df_btc['close'], mode='lines', name=f\"{symbol_dropdown.value} Close\", line=dict(color='#00c851', width=1)),\n",
    "            row=1,\n",
    "            col=1,\n",
    "            secondary_y=False,\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=df_btc.index, y=df_btc[f'ma_{MA_PERIOD}_shifted'], mode='lines', name=f\"MA {MA_PERIOD} (shifted)\", line=dict(color='blue', width=1)),\n",
    "            row=1,\n",
    "            col=1,\n",
    "            secondary_y=False,\n",
    "        )\n",
    "\n",
    "        # Volume sur la premi√®re rang√©e (row=1) - axe Y secondaire\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=df_btc.index, y=df_btc['volume'], mode='lines', name='Volume', line=dict(color='green', width=1), opacity=0.3),\n",
    "            row=1,\n",
    "            col=1,\n",
    "            secondary_y=True,\n",
    "        )\n",
    "\n",
    "        # Diff√©rence sur la deuxi√®me rang√©e (row=2)\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=df_btc.index, y=df_btc['diff_close_ma'], mode='lines', name='Close - MA (shifted)', line=dict(color='red', width=1)),\n",
    "            row=2,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "        # === ANALYSE PAR ONDELETTES MORLET (alternative √† Daubechies) ===\n",
    "        try:\n",
    "            # Pr√©parer les donn√©es pour l'analyse par ondelettes (utiliser le signal de diff√©rence)\n",
    "            # Utiliser la diff√©rence Close - MA pour analyser les d√©viations par rapport √† la tendance\n",
    "            signal = df_btc['diff_close_ma'].dropna().values\n",
    "            time_index = df_btc['diff_close_ma'].dropna().index\n",
    "            \n",
    "            # R√©duire le signal pour √©viter des calculs trop lourds\n",
    "            max_signal_length = 1024  # Limiter pour performance\n",
    "            if len(signal) > max_signal_length:\n",
    "                step = len(signal) // max_signal_length\n",
    "                signal = signal[::step]\n",
    "                time_index = time_index[::step]\n",
    "            \n",
    "            # Param√®tres pour l'analyse par ondelettes optimis√©s pour basses fr√©quences\n",
    "            wavelet = 'morl'  # Ondelette de Morlet (alternative √† Daubechies)\n",
    "            # √âtendre la plage d'√©chelles vers les grandes valeurs pour capturer les basses fr√©quences\n",
    "            scales = np.geomspace(1, 256, 80)  # Plus d'√©chelles avec extension vers 256\n",
    "            \n",
    "            # Calculer la transform√©e en ondelettes continue (CWT)\n",
    "            coefficients, frequencies = pywt.cwt(signal, scales, wavelet)\n",
    "            \n",
    "            # Calculer les pseudo-fr√©quences pour Morlet\n",
    "            # Pour Morlet, la fr√©quence est approximativement 1/scale\n",
    "            pseudo_frequencies = 1.0 / scales  # Fr√©quence inversement proportionnelle √† l'√©chelle\n",
    "            \n",
    "            # Cr√©er le scalogramme avec normalisation logarithmique pour am√©liorer le contraste des basses fr√©quences\n",
    "            scalogram = np.abs(coefficients)\n",
    "            \n",
    "            # Normalisation logarithmique pour accentuer les faibles amplitudes (basses fr√©quences)\n",
    "            # Ajouter une petite constante pour √©viter log(0)\n",
    "            epsilon = np.max(scalogram) * 1e-6\n",
    "            scalogram_log = np.log10(scalogram + epsilon)\n",
    "            \n",
    "            # Filtrer pour se concentrer sur les basses fr√©quences (√©chelles > 8, soit fr√©quences < 0.125)\n",
    "            low_freq_mask = scales >= 8  # Garder les √©chelles >= 8\n",
    "            scales_filtered = scales[low_freq_mask]\n",
    "            pseudo_frequencies_filtered = pseudo_frequencies[low_freq_mask]\n",
    "            scalogram_filtered = scalogram_log[low_freq_mask, :]\n",
    "            \n",
    "            # Ajouter le scalogramme comme heatmap avec colormap optimis√©e pour le contraste\n",
    "            fig.add_trace(\n",
    "                go.Heatmap(\n",
    "                    x=time_index,\n",
    "                    y=pseudo_frequencies_filtered,\n",
    "                    z=scalogram_filtered,\n",
    "                    colorscale='Plasma',  # Plasma offre un meilleur contraste pour les faibles valeurs\n",
    "                    name='Ondelettes Morlet (Basses Fr√©q.)',\n",
    "                    showscale=True,\n",
    "                    colorbar=dict(title=\"Log Amplitude\", x=1.02, len=0.2, y=0.4)\n",
    "                ),\n",
    "                row=3,\n",
    "                col=1\n",
    "            )\n",
    "            \n",
    "            print(f\"Analyse ondelettes r√©ussie !\")\n",
    "            print(f\"Wavelet: {wavelet} (Morlet)\")\n",
    "            print(f\"Signal analys√©: Diff√©rence (Close - MA) pour capturer les d√©viations\")\n",
    "            print(f\"Nombre d'√©chelles totales: {len(scales)}\")\n",
    "            print(f\"Nombre d'√©chelles affich√©es (basses fr√©q.): {len(scales_filtered)}\")\n",
    "            print(f\"Points de signal: {len(signal)}\")\n",
    "            print(f\"Plage de fr√©quences affich√©es: {pseudo_frequencies_filtered.min():.6f} - {pseudo_frequencies_filtered.max():.6f}\")\n",
    "            print(f\"√âchelles affich√©es: {scales_filtered.min():.1f} - {scales_filtered.max():.1f}\")\n",
    "            print(f\"Normalisation: Logarithmique (log10) pour am√©liorer contraste basses fr√©quences\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'Erreur analyse ondelettes: {e}')\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            # Afficher un message sur le graphique en cas d'erreur\n",
    "            fig.add_annotation(text=f'Erreur ondelettes: {str(e)[:50]}', xref='paper', yref='paper', x=0.5, y=0.4, showarrow=False, row=3, col=1)\n",
    "\n",
    "        # Ajout d'une analyse de Fourier (FFT) sur la s√©rie de diff√©rences\n",
    "        try:\n",
    "            N = len(difference_values)\n",
    "            if N >= 4:\n",
    "                # Detrend simple: retirer la moyenne\n",
    "                vals = difference_values - np.mean(difference_values)\n",
    "                # FFT (real-valued optimis√©e)\n",
    "                fft_vals = np.fft.rfft(vals)\n",
    "                fft_freqs = np.fft.rfftfreq(N, d=1.0)  # cycles per sample\n",
    "                fft_amp = np.abs(fft_vals)\n",
    "\n",
    "                # Convertir fr√©quence -> p√©riode (en nombre d'√©chantillons). On ignore la fr√©quence 0 (DC) pour la p√©riode.\n",
    "                nonzero = fft_freqs > 0\n",
    "                periods = np.full_like(fft_freqs, np.nan, dtype=float)\n",
    "                periods[nonzero] = 1.0 / fft_freqs[nonzero]\n",
    "\n",
    "                # Pr√©parer donn√©es pour affichage (exclure DC et utiliser les fr√©quences)\n",
    "                plot_mask = nonzero\n",
    "                plot_freqs = fft_freqs[plot_mask]  # Utiliser les fr√©quences au lieu des p√©riodes\n",
    "                plot_amp = fft_amp[plot_mask]\n",
    "\n",
    "                # Limiter la plage de fr√©quence affich√©e pour correspondre aux ondelettes\n",
    "                # Garder seulement les basses fr√©quences similaires aux ondelettes (< 0.125)\n",
    "                max_freq = 0.5  # Limiter √† 0.5 pour avoir un bon d√©tail des basses fr√©quences\n",
    "                keep = plot_freqs <= max_freq\n",
    "                plot_freqs = plot_freqs[keep]\n",
    "                plot_amp = plot_amp[keep]\n",
    "\n",
    "                # Tracer le spectre (Amplitude) en fonction de la fr√©quence - SUR LA 4√®me RANG√âE\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(x=plot_freqs, y=plot_amp, mode='lines', name='FFT Amplitude', line=dict(color='purple', width=1)),\n",
    "                    row=4,\n",
    "                    col=1,\n",
    "                )\n",
    "\n",
    "                # Reconstruction avec filtre des top fr√©quences dominantes\n",
    "                try:\n",
    "                    # Reconstruction compl√®te (sans filtrage)\n",
    "                    recon_full = np.fft.irfft(fft_vals, n=N)\n",
    "                    recon_full = recon_full + np.mean(difference_values)\n",
    "                    \n",
    "                    # Filtre pour garder seulement les top N pics dominants\n",
    "                    fft_vals_filtered = np.zeros_like(fft_vals)\n",
    "                    # Garder la composante DC (fr√©quence 0)\n",
    "                    fft_vals_filtered[0] = fft_vals[0]\n",
    "                    \n",
    "                    # Identifier les top N pics (excluant DC)\n",
    "                    if len(fft_amp) > 1:\n",
    "                        k = min(TOP_FREQUENCIES, len(fft_amp) - 1)  # -1 pour exclure DC\n",
    "                        # Indices des top k amplitudes (excluant DC √† l'index 0)\n",
    "                        top_idx = np.argsort(fft_amp[1:])[-k:] + 1  # +1 pour compenser l'exclusion de DC\n",
    "                        # Garder seulement ces fr√©quences\n",
    "                        fft_vals_filtered[top_idx] = fft_vals[top_idx]\n",
    "                    \n",
    "                    # Reconstruction filtr√©e\n",
    "                    recon_filtered = np.fft.irfft(fft_vals_filtered, n=N)\n",
    "                    recon_filtered = recon_filtered + np.mean(difference_values)\n",
    "                    \n",
    "                    # Mesures d'erreur pour les deux reconstructions\n",
    "                    mse_full = np.mean((recon_full - difference_values)**2)\n",
    "                    mse_filtered = np.mean((recon_filtered - difference_values)**2)\n",
    "                    max_err_full = np.max(np.abs(recon_full - difference_values))\n",
    "                    max_err_filtered = np.max(np.abs(recon_filtered - difference_values))\n",
    "                    \n",
    "                    # Tracer la reconstruction filtr√©e (top N)\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(x=diff_series.index, y=recon_filtered, mode='lines', name=f'Reconstruction top {TOP_FREQUENCIES}', line=dict(color='orange', width=1)),\n",
    "                        row=2, col=1\n",
    "                    )\n",
    "                    \n",
    "                    print(f\"FFT - Reconstruction compl√®te - MSE: {mse_full:.3e}, Max Error: {max_err_full:.3e}\")\n",
    "                    print(f\"FFT - Reconstruction top {TOP_FREQUENCIES} - MSE: {mse_filtered:.3e}, Max Error: {max_err_filtered:.3e}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Erreur reconstruction: {e}\")\n",
    "\n",
    "                # Annoter les pics dominants (top N) pour aider l'interpr√©tation - SUR LA 4√®me RANG√âE\n",
    "                try:\n",
    "                    k = min(5, len(plot_amp))  # Top 5 seulement pour les annotations\n",
    "                    top_idx = np.argsort(plot_amp)[-k:][::-1]\n",
    "                    top_freqs = plot_freqs[top_idx]  # Utiliser les fr√©quences\n",
    "                    top_amp = plot_amp[top_idx]\n",
    "                    # Ajouter des marqueurs et labels\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(x=top_freqs, y=top_amp, mode='markers+text', text=[f\"{f:.3f}\" for f in top_freqs], textposition='top center', marker=dict(color='red', size=6), showlegend=False),\n",
    "                        row=4,\n",
    "                        col=1\n",
    "                    )\n",
    "                except Exception:\n",
    "                    pass\n",
    "            else:\n",
    "                # Trop peu de points pour une FFT fiable - SUR LA 4√®me RANG√âE\n",
    "                fig.add_annotation(text='N trop petit pour FFT', xref='paper', yref='paper', x=0.5, y=0.05, showarrow=False, row=4, col=1)\n",
    "        except Exception as e:\n",
    "            print('Erreur FFT:', e)\n",
    "\n",
    "        # Ajouter une ligne horizontale fine et pointill√©e (y=0) sur la rang√©e des diff√©rences (row=2)\n",
    "        try:\n",
    "            fig.add_hline(y=0, line=dict(color='gray', dash='dot', width=1), row=2, col=1)\n",
    "        except Exception:\n",
    "            try:\n",
    "                fig.add_shape(\n",
    "                    type='line',\n",
    "                    x0=df_btc.index.min(), x1=df_btc.index.max(),\n",
    "                    y0=0, y1=0,\n",
    "                    xref='x', yref='y',\n",
    "                    line=dict(color='gray', dash='dot', width=1),\n",
    "                    row=2, col=1,\n",
    "                )\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        # Layout improvements\n",
    "        fig.update_layout(\n",
    "            height=1600,  # Augment√© pour 4 graphiques\n",
    "            showlegend=False,\n",
    "            legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1),\n",
    "            hovermode='x unified',\n",
    "            title_text=f\"{symbol_dropdown.value} ({DUREE_JOURS}d @ {INTERVAL}) - Close, MA {MA_PERIOD}, Volume, Diff, Ondelettes & FFT\", \n",
    "            margin=dict(l=60, r=60, t=80, b=120),\n",
    "        )\n",
    "\n",
    "        # Axis labels: row 1 = Price (primaire) + Volume (secondaire), row 2 = Diff, row 3 = Ondelettes, row 4 = FFT\n",
    "        fig.update_yaxes(title_text='Price', row=1, col=1, secondary_y=False)\n",
    "        fig.update_yaxes(title_text='Volume', row=1, col=1, secondary_y=True)\n",
    "        fig.update_yaxes(title_text='Diff', row=2, col=1)\n",
    "        fig.update_yaxes(title_text='Fr√©quence (1/√©chelle) - Focus Basses Fr√©q.', row=3, col=1, type='log')  # √âchelle logarithmique pour les fr√©quences\n",
    "        fig.update_yaxes(title_text='Amplitude', row=4, col=1)\n",
    "\n",
    "        # Configure X-axis appearance for datetime subplot\n",
    "        date_xargs = dict(type='date', tickformat=\"%Y-%m-%d\\n%H:%M\", tickangle=-45, tickfont=dict(size=10), nticks=8, ticks='outside', showgrid=False, showticklabels=True, title_standoff=20)\n",
    "        try:\n",
    "            x0 = df_btc.index.min()\n",
    "            x1 = df_btc.index.max()\n",
    "            \n",
    "            # Synchroniser les axes X des trois premiers graphiques (row 1, 2 et 3)\n",
    "            # Les trois auront la m√™me plage et seront li√©s pour le zoom/pan\n",
    "            fig.update_xaxes(range=[x0, x1], title_text='', matches='x3', **date_xargs, row=1, col=1)\n",
    "            fig.update_xaxes(range=[x0, x1], title_text='', matches='x3', **date_xargs, row=2, col=1)\n",
    "            fig.update_xaxes(range=[x0, x1], title_text='Time', **date_xargs, row=3, col=1)\n",
    "            \n",
    "        except Exception:\n",
    "            fig.update_xaxes(title_text='Time', **date_xargs, row=3, col=1)\n",
    "\n",
    "        # X-axis pour le spectre: fr√©quence (m√™me unit√© que l'axe Y des ondelettes) - SUR LA 4√®me RANG√âE\n",
    "        try:\n",
    "            fig.update_xaxes(title_text='Fr√©quence (cycles/√©chantillon)', row=4, col=1, type='log')\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # Affichage simple\n",
    "        try:\n",
    "            fig.show(renderer='vscode')\n",
    "        except Exception as e:\n",
    "            print(\"Erreur: impossible d'afficher la figure avec le renderer 'vscode'.\")\n",
    "            print(\"D√©tail: \", str(e))\n",
    "\n",
    "# Connecter les callbacks aux boutons\n",
    "download_button.on_click(on_download_click)\n",
    "visualize_button.on_click(on_visualize_click)\n",
    "\n",
    "# Fonction pour mettre √† jour l'affichage de la configuration\n",
    "def update_config_display():\n",
    "    with output_area:\n",
    "        clear_output(wait=False)\n",
    "        print(\"Configuration actuelle:\")\n",
    "        print(f\"- Symbole: {symbol_dropdown.value}\")\n",
    "        print(f\"- Dur√©e d'analyse: {duree_slider.value} jours\")\n",
    "        print(f\"- Intervalle: {interval_dropdown.value}\")\n",
    "        print(f\"- Date de fin: {end_date_picker.value.strftime('%Y-%m-%d') if end_date_picker.value else 'Non d√©finie'}\")\n",
    "        print(\"\\nCliquez sur 'T√©l√©charger les donn√©es' pour commencer.\")\n",
    "\n",
    "# Callback pour mettre √† jour l'affichage quand les sliders changent\n",
    "def on_slider_change(change):\n",
    "    update_config_display()\n",
    "\n",
    "duree_slider.observe(on_slider_change, names='value')\n",
    "interval_dropdown.observe(on_slider_change, names='value')\n",
    "symbol_dropdown.observe(on_slider_change, names='value')\n",
    "end_date_picker.observe(on_slider_change, names='value')\n",
    "\n",
    "# Afficher les widgets\n",
    "display(HBox([symbol_dropdown, duree_slider, interval_dropdown, end_date_picker, download_button, visualize_button]))\n",
    "display(output_area)\n",
    "\n",
    "# Affichage initial de la configuration\n",
    "update_config_display()\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def download_binance_vision_data(symbol=SYMBOL, interval=INTERVAL, days_back=DUREE_JOURS, end_date_str=None):\n",
    "\n",
    "    # R√©solution de la date de fin\n",
    "    if end_date_str is None:\n",
    "        try:\n",
    "            end_date_str = END_DATE  # variable globale d√©finie dans la cellule de config\n",
    "        except NameError:\n",
    "            end_date_str = None\n",
    "\n",
    "    if end_date_str:\n",
    "        try:\n",
    "            end_date = datetime.strptime(end_date_str, '%Y-%m-%d')\n",
    "        except Exception:\n",
    "            print(f\"Format END_DATE invalide: {end_date_str}. Utilisation de datetime.now().\")\n",
    "            end_date = datetime.now()\n",
    "    else:\n",
    "        end_date = datetime.now()\n",
    "\n",
    "    # Calculer la date de d√©but\n",
    "    start_date = end_date - timedelta(days=days_back)\n",
    "\n",
    "    # Construire la liste des dates √† t√©l√©charger\n",
    "    dates = []\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        dates.append(current_date.strftime('%Y-%m-%d'))\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    # Cr√©ation des widgets de progression\n",
    "    progress_bar = FloatProgress(\n",
    "        value=0,\n",
    "        min=0,\n",
    "        max=len(dates),\n",
    "        bar_style='info',\n",
    "        style={'bar_color': '#00c851'},\n",
    "        orientation='horizontal'\n",
    "    )\n",
    "    \n",
    "    # status_label = HTML(value=f\"<b>Pr√©paration du t√©l√©chargement de {len(dates)} fichiers...</b>\")\n",
    "    \n",
    "    # Conteneur pour afficher la barre de progression\n",
    "    progress_widget = VBox([progress_bar])\n",
    "    display(progress_widget)\n",
    "\n",
    "    all_data = []\n",
    "    success_count = 0\n",
    "    total_periods = 0\n",
    "\n",
    "    from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "    def fetch_for_date(date_str):\n",
    "        \"\"\"T√©l√©charge et retourne un tuple (date_str, df_day or None, error_message or None, periods_count)\"\"\"\n",
    "        url = f\"https://data.binance.vision/data/spot/daily/klines/{symbol}/{interval}/{symbol}-{interval}-{date_str}.zip\"\n",
    "        try:\n",
    "            # Petite trace locale (renvoy√©e pour agr√©gation)\n",
    "            resp = requests.get(url, timeout=30)\n",
    "            if resp.status_code == 200:\n",
    "                with zipfile.ZipFile(BytesIO(resp.content)) as zip_file:\n",
    "                    csv_filename = f\"{symbol}-{interval}-{date_str}.csv\"\n",
    "                    if csv_filename in zip_file.namelist():\n",
    "                        csv_content = zip_file.read(csv_filename)\n",
    "                        df_day = pd.read_csv(BytesIO(csv_content), header=None, names=[\n",
    "                            'timestamp', 'open', 'high', 'low', 'close', 'volume',\n",
    "                            'close_time', 'quote_asset_volume', 'number_of_trades',\n",
    "                            'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'\n",
    "                        ])\n",
    "                        return (date_str, df_day, None, len(df_day))\n",
    "                    else:\n",
    "                        return (date_str, None, 'CSV not found in ZIP', 0)\n",
    "            else:\n",
    "                return (date_str, None, f'HTTP {resp.status_code}', 0)\n",
    "        except requests.exceptions.RequestException:\n",
    "            return (date_str, None, 'Network error', 0)\n",
    "        except zipfile.BadZipFile:\n",
    "            return (date_str, None, 'Bad ZIP', 0)\n",
    "        except Exception as e:\n",
    "            return (date_str, None, str(e)[:200], 0)\n",
    "\n",
    "    # Param√®tres de parall√©lisme: limiter le nombre de threads raisonnablement\n",
    "    max_workers = min(12, max(4, len(dates)))\n",
    "    completed_count = 0\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as exe:\n",
    "        future_to_date = {exe.submit(fetch_for_date, d): d for d in dates}\n",
    "        for fut in as_completed(future_to_date):\n",
    "            date_str = future_to_date[fut]\n",
    "            try:\n",
    "                d, df_day, err, periods = fut.result()\n",
    "                completed_count += 1\n",
    "                \n",
    "                # Mise √† jour de la barre de progression\n",
    "                progress_bar.value = completed_count\n",
    "                \n",
    "                if df_day is not None:\n",
    "                    # --- Normalisation des timestamps: uniformiser en microsecondes (us) ---\n",
    "                    try:\n",
    "                        # S'assurer que la colonne 'timestamp' existe et est num√©rique\n",
    "                        if 'timestamp' not in df_day.columns:\n",
    "                            # si les colonnes sont index√©es num√©riquement, la premi√®re colonne est le timestamp\n",
    "                            df_day.rename(columns={0: 'timestamp'}, inplace=True)\n",
    "                        df_day['timestamp'] = pd.to_numeric(df_day['timestamp'], errors='coerce')\n",
    "                    except Exception:\n",
    "                        pass\n",
    "\n",
    "                    try:\n",
    "                        # D√©tecter les timestamps inf√©rieurs au seuil (2025-01-01)\n",
    "                        threshold_dt = datetime(2025, 1, 1)\n",
    "                        # Seuil en millisecondes correspondant √† 2025-01-01\n",
    "                        threshold_ms = int(threshold_dt.timestamp() * 1000)\n",
    "\n",
    "                        # Heuristique: si la majorit√© des timestamps sont < threshold_ms*10, ils sont probablement en ms\n",
    "                        max_ts = pd.to_numeric(df_day['timestamp'], errors='coerce').max()\n",
    "                        if pd.notna(max_ts):\n",
    "                            # Si le maximum observ√© est inf√©rieur √† threshold_ms * 10, on suppose que les valeurs sont en ms\n",
    "                            if max_ts < threshold_ms * 10:\n",
    "                                mask_ms = pd.to_numeric(df_day['timestamp'], errors='coerce') < (threshold_ms * 10)\n",
    "                                if mask_ms.any():\n",
    "                                    df_day.loc[mask_ms, 'timestamp'] = pd.to_numeric(df_day.loc[mask_ms, 'timestamp'], errors='coerce') * 1000\n",
    "                    except Exception as e:\n",
    "                        print(f\"‚ö† Erreur lors de la normalisation des timestamps: {e}\")\n",
    "\n",
    "                    all_data.append(df_day)\n",
    "                    success_count += 1\n",
    "                    total_periods += periods\n",
    "                    \n",
    "            except Exception as e:\n",
    "                completed_count += 1\n",
    "                progress_bar.value = completed_count\n",
    "               \n",
    "    # Finalisation de la barre de progression\n",
    "    progress_bar.bar_style = 'success' if success_count > 0 else 'danger'\n",
    "   \n",
    "    # Petit d√©lai global pour rester poli si n√©cessaire\n",
    "    time.sleep(0.1)\n",
    "\n",
    "    if all_data:\n",
    "        # Combiner toutes les donn√©es\n",
    "        combined_df = pd.concat(all_data, ignore_index=True)\n",
    "        return combined_df.to_dict('records')\n",
    "    else:\n",
    "        print(\"Aucune donn√©e r√©cup√©r√©e via Binance Vision\")\n",
    "        return []\n",
    "\n",
    "def create_dataframe(data, symbol_name):\n",
    "    if not data:\n",
    "        print(f\"Aucune donn√©e disponible pour {symbol_name}\")\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    df = pd.DataFrame(data, columns=[\n",
    "        'timestamp', 'open', 'high', 'low', 'close', 'volume',\n",
    "        'close_time', 'quote_asset_volume', 'number_of_trades',\n",
    "        'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'\n",
    "    ])\n",
    "    \n",
    "    # Conversion des types\n",
    "    for col in ['open', 'high', 'low', 'close', 'volume']:\n",
    "        df[col] = df[col].astype(float)\n",
    "    \n",
    "    # Gestion des timestamps - Binance Vision utilise diff√©rents formats\n",
    "    timestamp_converted = False\n",
    "    \n",
    "    try:\n",
    "        # Essai avec microsecondes (format attendu apr√®s normalisation)\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='us')\n",
    "        timestamp_converted = True\n",
    "        # print(\"‚úì Timestamps convertis depuis microsecondes\")\n",
    "    except (ValueError, pd.errors.OutOfBoundsDatetime, OverflowError):\n",
    "        try:\n",
    "            # Essai avec millisecondes (fallback)\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "            timestamp_converted = True\n",
    "        except (ValueError, pd.errors.OutOfBoundsDatetime, OverflowError):\n",
    "            try:\n",
    "                # Essai avec secondes\n",
    "                df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "                timestamp_converted = True\n",
    "            except (ValueError, pd.errors.OutOfBoundsDatetime, OverflowError):\n",
    "                try:\n",
    "                    # Si les valeurs sont trop grandes, diviser par 1000000 (microsecondes vers secondes)\n",
    "                    df['timestamp'] = pd.to_datetime(df['timestamp'] / 1000000, unit='s')\n",
    "                    timestamp_converted = True\n",
    "                except (ValueError, pd.errors.OutOfBoundsDatetime, OverflowError):\n",
    "                    print(\"‚úó Impossible de convertir les timestamps\")\n",
    "\n",
    "    if not timestamp_converted:\n",
    "        print(f\"‚úó Erreur: Impossible de traiter les timestamps pour {symbol_name}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # V√©rifier la plausibilit√© des dates\n",
    "    min_date = df['timestamp'].min()\n",
    "    max_date = df['timestamp'].max()\n",
    "    \n",
    "    if min_date.year < 2009 or max_date.year > 2030:\n",
    "        print(f\"‚ö† Dates suspectes d√©tect√©es: {min_date} √† {max_date}\")\n",
    "    \n",
    "    df.set_index('timestamp', inplace=True)\n",
    "    \n",
    "    # Supprimer les doublons et trier\n",
    "    df = df[~df.index.duplicated(keep='first')].sort_index()\n",
    "    \n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
