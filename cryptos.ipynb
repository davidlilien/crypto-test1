{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a6f201f1944d7eb08c0beba6ea1e48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='Symbole:', layout=Layout(width='120px')), Dropdown(layout=Layout(wi‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5355a897820342128e793d79232244ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "import warnings\n",
    "from ipywidgets import FloatProgress, HTML, VBox, IntSlider, Button, HBox, Label, Output\n",
    "from ipywidgets import Dropdown, DatePicker\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Widget pour s√©lectionner le symbole\n",
    "symbol_dropdown = Dropdown(\n",
    "    options=['BTCUSDT', 'ETHUSDT'],\n",
    "    value='BTCUSDT',\n",
    "    description='Symbole:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout={'width': '200px'}\n",
    ")\n",
    "duree_slider = IntSlider(\n",
    "    value=365,\n",
    "    min=1,\n",
    "    max=730,\n",
    "    step=1,\n",
    "    description='Dur√©e (jours):',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout={'width': '200px'}\n",
    ")\n",
    "\n",
    "# Widget pour s√©lectionner l'intervalle\n",
    "from ipywidgets import Dropdown\n",
    "interval_dropdown = Dropdown(\n",
    "    options=['1m', '5m', '15m', '30m', '1h', '2h', '4h', '6h', '8h', '12h', '1d', '3d', '1w', '1M'],\n",
    "    value='1h',\n",
    "    description='Intervalle:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout={'width': '200px'}\n",
    ")\n",
    "\n",
    "# Widget pour s√©lectionner la date de fin\n",
    "end_date_picker = DatePicker(\n",
    "    description='Date de fin:',\n",
    "    value=datetime.now().date(),\n",
    "    style={'description_width': 'initial'},\n",
    "    layout={'width': '200px'}\n",
    ")\n",
    "\n",
    "# Widget pour s√©lectionner la p√©riode de la moyenne mobile\n",
    "ma_period_slider = IntSlider(\n",
    "    value=24,\n",
    "    min=2,\n",
    "    max=200,\n",
    "    step=1,\n",
    "    description='MA P√©riode:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout={'width': '200px'}\n",
    ")\n",
    "\n",
    "# Widget pour s√©lectionner le nombre de pics FFT\n",
    "top_freq_slider = IntSlider(\n",
    "    value=200,\n",
    "    min=1,\n",
    "    max=500,\n",
    "    step=1,\n",
    "    description='FFT Pics:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout={'width': '200px'}\n",
    ")\n",
    "\n",
    "# Bouton pour lancer le t√©l√©chargement\n",
    "download_button = Button(\n",
    "    description='T√©l√©charger',\n",
    "    button_style='primary',\n",
    "    tooltip='Cliquez pour lancer le t√©l√©chargement des donn√©es Binance Vision'\n",
    ")\n",
    "\n",
    "# Bouton pour lancer la visualisation\n",
    "visualize_button = Button(\n",
    "    description='Visualiser',\n",
    "    button_style='success',\n",
    "    tooltip='Cliquez pour afficher les graphiques d\\'analyse (n√©cessite des donn√©es t√©l√©charg√©es)',\n",
    "    disabled=True  # D√©sactiv√© par d√©faut\n",
    ")\n",
    "\n",
    "# Zone de sortie pour les messages\n",
    "output_area = Output()\n",
    "\n",
    "# Variables globales (seront mises √† jour par les widgets)\n",
    "DUREE_JOURS = duree_slider.value\n",
    "INTERVAL = interval_dropdown.value\n",
    "SYMBOL = symbol_dropdown.value\n",
    "END_DATE = end_date_picker.value.strftime('%Y-%m-%d') if end_date_picker.value else datetime.now().strftime('%Y-%m-%d')\n",
    "MA_PERIOD = ma_period_slider.value\n",
    "TOP_FREQUENCIES = top_freq_slider.value\n",
    "\n",
    "# Initialiser les variables globales pour √©viter les erreurs\n",
    "btc_data = []\n",
    "df_btc = pd.DataFrame()\n",
    "\n",
    "# Fonction callback pour le bouton de t√©l√©chargement\n",
    "def on_download_click(b):\n",
    "    global DUREE_JOURS, INTERVAL, btc_data, df_btc\n",
    "    \n",
    "    # D√©sactiver le bouton et changer son texte pendant le t√©l√©chargement\n",
    "    original_button_text = download_button.description\n",
    "    download_button.description = '‚è≥ T√©l√©chargement...'\n",
    "    download_button.disabled = True\n",
    "    \n",
    "    try:\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            print(\"üì• T√©l√©chargement des donn√©es en cours...\")\n",
    "            print(f\"Symbole: {symbol_dropdown.value}, Dur√©e: {duree_slider.value} jours\")\n",
    "            print()\n",
    "            \n",
    "            # Mettre √† jour les variables globales\n",
    "            DUREE_JOURS = duree_slider.value\n",
    "            INTERVAL = interval_dropdown.value\n",
    "            SYMBOL = symbol_dropdown.value\n",
    "            END_DATE = end_date_picker.value.strftime('%Y-%m-%d') if end_date_picker.value else datetime.now().strftime('%Y-%m-%d')\n",
    "            \n",
    "            # Lancer le t√©l√©chargement\n",
    "            btc_data = download_binance_vision_data(SYMBOL, INTERVAL, DUREE_JOURS)\n",
    "            \n",
    "            # Cr√©er le DataFrame\n",
    "            df_btc = create_dataframe(btc_data, SYMBOL)\n",
    "            \n",
    "            if len(df_btc) > 0:\n",
    "                print(\"‚úÖ T√©l√©chargement termin√© avec succ√®s!\")\n",
    "                print(f\"Donn√©es r√©cup√©r√©es: {len(df_btc)} p√©riodes\")\n",
    "                print(f\"P√©riode: {df_btc.index.min()} √† {df_btc.index.max()}\")\n",
    "                # Activer le bouton de visualisation\n",
    "                visualize_button.disabled = False\n",
    "                print(\"\\nüîÑ G√©n√©ration automatique de la visualisation...\")\n",
    "                print()\n",
    "                \n",
    "                # Lancer automatiquement la visualisation\n",
    "                clear_output(wait=True)\n",
    "                create_visualization()\n",
    "            else:\n",
    "                print(\"\\n‚ùå √âchec du t√©l√©chargement - Aucune donn√©e r√©cup√©r√©e\")\n",
    "                visualize_button.disabled = True\n",
    "    finally:\n",
    "        # R√©activer le bouton et remettre le texte original\n",
    "        download_button.description = original_button_text\n",
    "        download_button.disabled = False\n",
    "\n",
    "# Fonction callback pour le bouton de visualisation\n",
    "def on_visualize_click(b):\n",
    "    global df_btc\n",
    "    \n",
    "    # D√©sactiver le bouton et changer son texte pendant le calcul\n",
    "    original_button_text = visualize_button.description\n",
    "    visualize_button.description = '‚è≥ Calcul en cours...'\n",
    "    visualize_button.disabled = True\n",
    "    \n",
    "    try:\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            print(\"üîÑ G√©n√©ration des visualisations en cours...\")\n",
    "            print(f\"Analyse de {len(df_btc)} p√©riodes de {symbol_dropdown.value}\")\n",
    "            print()\n",
    "            \n",
    "            # Ex√©cuter la visualisation\n",
    "            create_visualization()\n",
    "            \n",
    "            print(\"‚úÖ Visualisation termin√©e !\")\n",
    "    finally:\n",
    "        # R√©activer le bouton et remettre le texte original\n",
    "        visualize_button.description = original_button_text\n",
    "        visualize_button.disabled = False\n",
    "\n",
    "# Fonction pour cr√©er les visualisations\n",
    "def create_visualization():\n",
    "    global MA_PERIOD, TOP_FREQUENCIES  # Acc√©der aux variables globales\n",
    "    \n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "    import numpy as np\n",
    "    import pywt  # PyWavelets pour l'analyse par ondelettes\n",
    "\n",
    "    # Param√®tres configurables\n",
    "    # MA_PERIOD et TOP_FREQUENCIES sont maintenant d√©finis globalement par les widgets\n",
    "\n",
    "    if len(df_btc) > 0:\n",
    "        print(\"üìä Calcul des moyennes mobiles...\")\n",
    "        # Calculer la moyenne mobile sur les MA_PERIOD derni√®res p√©riodes\n",
    "        df_btc[f'ma_{MA_PERIOD}'] = df_btc['close'].rolling(window=MA_PERIOD).mean()\n",
    "        # D√©calage vers la gauche pour aligner (la fin des donn√©es n'est pas importante)\n",
    "        decalage = MA_PERIOD // 2\n",
    "        df_btc[f'ma_{MA_PERIOD}_shifted'] = df_btc[f'ma_{MA_PERIOD}'].shift(-decalage)\n",
    "\n",
    "        # Calculer la diff√©rence entre close et la MA d√©cal√©e\n",
    "        df_btc['diff_close_ma'] = df_btc['close'] - df_btc[f'ma_{MA_PERIOD}_shifted']\n",
    "\n",
    "        # S√©rie de diff√©rences (sans NaN)\n",
    "        diff_series = df_btc['diff_close_ma'].dropna()\n",
    "        difference_values = diff_series.values\n",
    "\n",
    "        # --- Cr√©ation de quatre subplots empil√©s (prix+volume, diff temporelle, ondelettes, spectre) ---\n",
    "        # Le premier subplot aura un axe Y secondaire pour le volume\n",
    "        fig = make_subplots(\n",
    "            rows=4,\n",
    "            cols=1,\n",
    "            shared_xaxes=False,  # On va g√©rer manuellement la synchronisation\n",
    "            vertical_spacing=0.08,  # Augment√© pour √©viter le d√©bordement des labels X\n",
    "            specs=[[{\"secondary_y\": True}],   # Axe Y secondaire pour le volume\n",
    "                   [{\"secondary_y\": False}], \n",
    "                   [{\"secondary_y\": False}],  # Ondelettes\n",
    "                   [{\"secondary_y\": False}]],\n",
    "            subplot_titles=('Prix, Moyenne Mobile & Volume', 'Diff√©rence (Close - MA) + FFT Reconstruction', 'Ondelettes sur Diff√©rence', 'Spectre FFT (P√©riodes)')\n",
    "        )\n",
    "\n",
    "        # Prix + MA sur la premi√®re rang√©e (row=1) - axe Y primaire\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=df_btc.index, y=df_btc['close'], mode='lines', name=f\"{symbol_dropdown.value} Close\", line=dict(color='#00c851', width=1)),\n",
    "            row=1,\n",
    "            col=1,\n",
    "            secondary_y=False,\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=df_btc.index, y=df_btc[f'ma_{MA_PERIOD}_shifted'], mode='lines', name=f\"MA {MA_PERIOD} (shifted)\", line=dict(color='blue', width=1)),\n",
    "            row=1,\n",
    "            col=1,\n",
    "            secondary_y=False,\n",
    "        )\n",
    "\n",
    "        # Volume sur la premi√®re rang√©e (row=1) - axe Y secondaire\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=df_btc.index, y=df_btc['volume'], mode='lines', name='Volume', line=dict(color='green', width=1), opacity=0.3),\n",
    "            row=1,\n",
    "            col=1,\n",
    "            secondary_y=True,\n",
    "        )\n",
    "\n",
    "        # Diff√©rence sur la deuxi√®me rang√©e (row=2)\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=df_btc.index, y=df_btc['diff_close_ma'], mode='lines', name='Close - MA (shifted)', line=dict(color='red', width=1)),\n",
    "            row=2,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "        # === ANALYSE PAR ONDELETTES MORLET (alternative √† Daubechies) ===\n",
    "        print(\"üåä Analyse par ondelettes en cours...\")\n",
    "        try:\n",
    "            # Pr√©parer les donn√©es pour l'analyse par ondelettes (utiliser le signal de diff√©rence)\n",
    "            # Utiliser la diff√©rence Close - MA pour analyser les d√©viations par rapport √† la tendance\n",
    "            signal = df_btc['diff_close_ma'].dropna().values\n",
    "            time_index = df_btc['diff_close_ma'].dropna().index\n",
    "            \n",
    "            # R√©duire le signal pour √©viter des calculs trop lourds\n",
    "            max_signal_length = 1024  # Limiter pour performance\n",
    "            if len(signal) > max_signal_length:\n",
    "                step = len(signal) // max_signal_length\n",
    "                signal = signal[::step]\n",
    "                time_index = time_index[::step]\n",
    "            \n",
    "            # Param√®tres pour l'analyse par ondelettes optimis√©s pour basses fr√©quences\n",
    "            wavelet = 'morl'  # Ondelette de Morlet (alternative √† Daubechies)\n",
    "            # √âtendre la plage d'√©chelles vers les grandes valeurs pour capturer les basses fr√©quences\n",
    "            scales = np.geomspace(1, 256, 80)  # Plus d'√©chelles avec extension vers 256\n",
    "            \n",
    "            # Calculer la transform√©e en ondelettes continue (CWT)\n",
    "            coefficients, frequencies = pywt.cwt(signal, scales, wavelet)\n",
    "            \n",
    "            # Calculer les pseudo-fr√©quences pour Morlet\n",
    "            # Pour Morlet, la fr√©quence est approximativement 1/scale\n",
    "            pseudo_frequencies = 1.0 / scales  # Fr√©quence inversement proportionnelle √† l'√©chelle\n",
    "            \n",
    "            # Cr√©er le scalogramme avec normalisation logarithmique pour am√©liorer le contraste des basses fr√©quences\n",
    "            scalogram = np.abs(coefficients)\n",
    "            \n",
    "            # Normalisation logarithmique pour accentuer les faibles amplitudes (basses fr√©quences)\n",
    "            # Ajouter une petite constante pour √©viter log(0)\n",
    "            epsilon = np.max(scalogram) * 1e-6\n",
    "            scalogram_log = np.log10(scalogram + epsilon)\n",
    "            \n",
    "            # Afficher toutes les fr√©quences (pas de filtrage)\n",
    "            scales_filtered = scales\n",
    "            pseudo_frequencies_filtered = pseudo_frequencies\n",
    "            scalogram_filtered = scalogram_log\n",
    "            \n",
    "            # Ajouter le scalogramme comme heatmap avec colormap optimis√©e pour le contraste\n",
    "            fig.add_trace(\n",
    "                go.Heatmap(\n",
    "                    x=time_index,\n",
    "                    y=scales_filtered,\n",
    "                    z=scalogram_filtered,\n",
    "                    colorscale='Plasma',  # Plasma offre un meilleur contraste pour les faibles valeurs\n",
    "                    name='Ondelettes Morlet',\n",
    "                    showscale=True,\n",
    "                    colorbar=dict(title=\"Log Amplitude\", x=1.02, len=0.2, y=0.4)\n",
    "                ),\n",
    "                row=3,\n",
    "                col=1\n",
    "            )\n",
    "            \n",
    "            #print(f\"Analyse ondelettes r√©ussie !\")\n",
    "            #print(f\"Wavelet: {wavelet} (Morlet)\")\n",
    "            #print(f\"Signal analys√©: Diff√©rence (Close - MA) pour capturer les d√©viations\")\n",
    "            #print(f\"Nombre d'√©chelles totales: {len(scales)}\")\n",
    "            #print(f\"Nombre d'√©chelles affich√©es: {len(scales_filtered)}\")\n",
    "            #print(f\"Points de signal: {len(signal)}\")\n",
    "            #print(f\"Plage de fr√©quences affich√©es: {pseudo_frequencies_filtered.min():.6f} - {pseudo_frequencies_filtered.max():.6f}\")\n",
    "            #print(f\"√âchelles affich√©es: {scales_filtered.min():.1f} - {scales_filtered.max():.1f}\")\n",
    "            #print(f\"Normalisation: Logarithmique (log10) pour am√©liorer contraste\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'Erreur analyse ondelettes: {e}')\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            # Afficher un message sur le graphique en cas d'erreur\n",
    "            fig.add_annotation(text=f'Erreur ondelettes: {str(e)[:50]}', xref='paper', yref='paper', x=0.5, y=0.4, showarrow=False, row=3, col=1)\n",
    "\n",
    "        # Ajout d'une analyse de Fourier (FFT) sur la s√©rie de diff√©rences\n",
    "        print(\"üìà Analyse FFT en cours...\")\n",
    "        try:\n",
    "            N = len(difference_values)\n",
    "            if N >= 4:\n",
    "                # Detrend simple: retirer la moyenne\n",
    "                vals = difference_values - np.mean(difference_values)\n",
    "                # FFT (real-valued optimis√©e)\n",
    "                fft_vals = np.fft.rfft(vals)\n",
    "                fft_freqs = np.fft.rfftfreq(N, d=1.0)  # cycles per sample\n",
    "                fft_amp = np.abs(fft_vals)\n",
    "\n",
    "                # Convertir fr√©quence -> p√©riode (en nombre d'√©chantillons). On ignore la fr√©quence 0 (DC) pour la p√©riode.\n",
    "                nonzero = fft_freqs > 0\n",
    "                periods = np.full_like(fft_freqs, np.nan, dtype=float)\n",
    "                periods[nonzero] = 1.0 / fft_freqs[nonzero]\n",
    "\n",
    "                # Pr√©parer donn√©es pour affichage (exclure DC et utiliser les p√©riodes pour une meilleure visualisation)\n",
    "                plot_mask = nonzero\n",
    "                plot_periods = periods[plot_mask]  # Utiliser les p√©riodes (plus intuitif que les fr√©quences)\n",
    "                plot_amp = fft_amp[plot_mask]\n",
    "\n",
    "                # Afficher toutes les p√©riodes (pas de filtrage)\n",
    "\n",
    "                # Tracer le spectre (Amplitude) en fonction de la p√©riode - SUR LA 4√®me RANG√âE\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(x=plot_periods, y=plot_amp, mode='lines', name='FFT Amplitude', line=dict(color='purple', width=1)),\n",
    "                    row=4,\n",
    "                    col=1,\n",
    "                )\n",
    "\n",
    "                #print(f\"FFT - Spectre complet affich√©\")\n",
    "                #print(f\"Nombre de fr√©quences analys√©es: {len(plot_periods)}\")\n",
    "                #print(f\"Plage de p√©riodes: {plot_periods.min():.1f}h - {plot_periods.max():.1f}h\")\n",
    "                #print(f\"P√©riodes principales (heures): {', '.join([f'{p:.1f}' for p in sorted(plot_periods[np.argsort(plot_amp)[-5:][::-1]])])}\")\n",
    "\n",
    "                # Reconstruction avec filtre des top fr√©quences dominantes\n",
    "                try:\n",
    "                    # Reconstruction compl√®te (sans filtrage)\n",
    "                    recon_full = np.fft.irfft(fft_vals, n=N)\n",
    "                    recon_full = recon_full + np.mean(difference_values)\n",
    "                    \n",
    "                    # Filtre pour garder seulement les top N pics dominants\n",
    "                    fft_vals_filtered = np.zeros_like(fft_vals)\n",
    "                    # Garder la composante DC (fr√©quence 0)\n",
    "                    fft_vals_filtered[0] = fft_vals[0]\n",
    "                    \n",
    "                    # Identifier les top N pics (excluant DC)\n",
    "                    if len(fft_amp) > 1:\n",
    "                        k = min(TOP_FREQUENCIES, len(fft_amp) - 1)  # -1 pour exclure DC\n",
    "                        # Indices des top k amplitudes (excluant DC √† l'index 0)\n",
    "                        top_idx = np.argsort(fft_amp[1:])[-k:] + 1  # +1 pour compenser l'exclusion de DC\n",
    "                        # Garder seulement ces fr√©quences\n",
    "                        fft_vals_filtered[top_idx] = fft_vals[top_idx]\n",
    "                    \n",
    "                    # Reconstruction filtr√©e\n",
    "                    recon_filtered = np.fft.irfft(fft_vals_filtered, n=N)\n",
    "                    recon_filtered = recon_filtered + np.mean(difference_values)\n",
    "                    \n",
    "                    # Mesures d'erreur pour les deux reconstructions\n",
    "                    mse_full = np.mean((recon_full - difference_values)**2)\n",
    "                    mse_filtered = np.mean((recon_filtered - difference_values)**2)\n",
    "                    max_err_full = np.max(np.abs(recon_full - difference_values))\n",
    "                    max_err_filtered = np.max(np.abs(recon_filtered - difference_values))\n",
    "                    \n",
    "                    # Tracer la reconstruction filtr√©e (top N)\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(x=diff_series.index, y=recon_filtered, mode='lines', name=f'Reconstruction top {TOP_FREQUENCIES}', line=dict(color='orange', width=1)),\n",
    "                        row=2, col=1\n",
    "                    )\n",
    "                    \n",
    "                    #print(f\"FFT - Reconstruction compl√®te - MSE: {mse_full:.3e}, Max Error: {max_err_full:.3e}\")\n",
    "                    #print(f\"FFT - Reconstruction top {TOP_FREQUENCIES} - MSE: {mse_filtered:.3e}, Max Error: {max_err_filtered:.3e}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Erreur reconstruction: {e}\")\n",
    "\n",
    "                # Annoter les pics dominants (top N) pour aider l'interpr√©tation - SUR LA 4√®me RANG√âE\n",
    "                try:\n",
    "                    k = TOP_FREQUENCIES  # Utiliser exactement TOP_FREQUENCIES pour les annotations\n",
    "                    top_idx = np.argsort(plot_amp)[-k:][::-1]\n",
    "                    top_periods = plot_periods[top_idx]  # Utiliser les p√©riodes\n",
    "                    top_amp = plot_amp[top_idx]\n",
    "                    # Ajouter des marqueurs (sans labels)\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(x=top_periods, y=top_amp, mode='markers', marker=dict(color='red', size=6), showlegend=False),\n",
    "                        row=4,\n",
    "                        col=1\n",
    "                    )\n",
    "                except Exception:\n",
    "                    pass\n",
    "            else:\n",
    "                # Trop peu de points pour une FFT fiable - SUR LA 4√®me RANG√âE\n",
    "                fig.add_annotation(text='N trop petit pour FFT', xref='paper', yref='paper', x=0.5, y=0.05, showarrow=False, row=4, col=1)\n",
    "        except Exception as e:\n",
    "            print('Erreur FFT:', e)\n",
    "\n",
    "        # Ajouter une ligne horizontale fine et pointill√©e (y=0) sur la rang√©e des diff√©rences (row=2)\n",
    "        try:\n",
    "            fig.add_hline(y=0, line=dict(color='gray', dash='dot', width=1), row=2, col=1)\n",
    "        except Exception:\n",
    "            try:\n",
    "                fig.add_shape(\n",
    "                    type='line',\n",
    "                    x0=df_btc.index.min(), x1=df_btc.index.max(),\n",
    "                    y0=0, y1=0,\n",
    "                    xref='x', yref='y',\n",
    "                    line=dict(color='gray', dash='dot', width=1),\n",
    "                    row=2, col=1,\n",
    "                )\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        # Layout improvements\n",
    "        fig.update_layout(\n",
    "            height=1600,  # Augment√© pour 4 graphiques\n",
    "            showlegend=False,\n",
    "            legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1),\n",
    "            hovermode='x unified',\n",
    "            # title_text=f\"{symbol_dropdown.value} ({DUREE_JOURS}d @ {INTERVAL}) - Close, MA {MA_PERIOD}, Volume, Diff, Ondelettes & FFT\", \n",
    "            margin=dict(l=60, r=60, t=80, b=120),\n",
    "        )\n",
    "\n",
    "        # Axis labels: row 1 = Price (primaire) + Volume (secondaire), row 2 = Diff, row 3 = Ondelettes, row 4 = FFT\n",
    "        fig.update_yaxes(title_text='Price', row=1, col=1, secondary_y=False)\n",
    "        fig.update_yaxes(title_text='Volume', row=1, col=1, secondary_y=True)\n",
    "        fig.update_yaxes(title_text='Diff', row=2, col=1)\n",
    "        fig.update_yaxes(title_text='P√©riode (heures)', row=3, col=1, type='log')  # √âchelle logarithmique pour les p√©riodes\n",
    "        fig.update_yaxes(title_text='Amplitude', row=4, col=1)\n",
    "\n",
    "        # Configure X-axis appearance for datetime subplot\n",
    "        date_xargs = dict(type='date', tickformat=\"%Y-%m-%d\\n%H:%M\", tickangle=-45, tickfont=dict(size=10), nticks=8, ticks='outside', showgrid=False, showticklabels=True, title_standoff=20)\n",
    "        try:\n",
    "            x0 = df_btc.index.min()\n",
    "            x1 = df_btc.index.max()\n",
    "            \n",
    "            # Synchroniser les axes X des trois premiers graphiques (row 1, 2 et 3)\n",
    "            # Les trois auront la m√™me plage et seront li√©s pour le zoom/pan\n",
    "            fig.update_xaxes(range=[x0, x1], title_text='', matches='x3', **date_xargs, row=1, col=1)\n",
    "            fig.update_xaxes(range=[x0, x1], title_text='', matches='x3', **date_xargs, row=2, col=1)\n",
    "            fig.update_xaxes(range=[x0, x1], title_text='', **date_xargs, row=3, col=1)\n",
    "            \n",
    "        except Exception:\n",
    "            fig.update_xaxes(title_text='Time', **date_xargs, row=3, col=1)\n",
    "\n",
    "        # X-axis pour le spectre: p√©riode en heures (plus intuitif que fr√©quence) - SUR LA 4√®me RANG√âE\n",
    "        try:\n",
    "            fig.update_xaxes(title_text='P√©riode (heures)', row=4, col=1, type='linear')\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # Affichage simple\n",
    "        print(\"üìä Affichage du graphique...\")\n",
    "        try:\n",
    "            fig.show(renderer='vscode')\n",
    "        except Exception as e:\n",
    "            print(\"Erreur: impossible d'afficher la figure avec le renderer 'vscode'.\")\n",
    "            print(\"D√©tail: \", str(e))\n",
    "\n",
    "# Connecter les callbacks aux boutons\n",
    "download_button.on_click(on_download_click)\n",
    "visualize_button.on_click(on_visualize_click)\n",
    "\n",
    "# Fonction pour mettre √† jour l'affichage de la configuration\n",
    "def update_config_display():\n",
    "    with output_area:\n",
    "        clear_output(wait=False)\n",
    "        #print(\"Configuration actuelle:\")\n",
    "        #print(f\"- Symbole: {symbol_dropdown.value}\")\n",
    "        #print(f\"- Dur√©e d'analyse: {duree_slider.value} jours\")\n",
    "        #print(f\"- Intervalle: {interval_dropdown.value}\")\n",
    "        #print(f\"- Date de fin: {end_date_picker.value.strftime('%Y-%m-%d') if end_date_picker.value else 'Non d√©finie'}\")\n",
    "        #print(\"\\nCliquez sur 'T√©l√©charger les donn√©es' pour commencer.\")\n",
    "\n",
    "# Callback pour mettre √† jour l'affichage quand les sliders changent\n",
    "def on_slider_change(change):\n",
    "    #update_config_display()\n",
    "    # Mettre √† jour les variables globales en temps r√©el\n",
    "    global DUREE_JOURS, INTERVAL, SYMBOL, END_DATE, MA_PERIOD, TOP_FREQUENCIES\n",
    "    DUREE_JOURS = duree_slider.value\n",
    "    INTERVAL = interval_dropdown.value\n",
    "    SYMBOL = symbol_dropdown.value\n",
    "    END_DATE = end_date_picker.value.strftime('%Y-%m-%d') if end_date_picker.value else datetime.now().strftime('%Y-%m-%d')\n",
    "    MA_PERIOD = ma_period_slider.value\n",
    "    TOP_FREQUENCIES = top_freq_slider.value\n",
    "    \n",
    "    # Si les donn√©es sont d√©j√† charg√©es, mettre √† jour automatiquement la visualisation\n",
    "    #if len(df_btc) > 0 and (change.owner == ma_period_slider or change.owner == top_freq_slider):\n",
    "    #    with output_area:\n",
    "    #        clear_output(wait=True)\n",
    "    #        print(f\"=== MISE √Ä JOUR DE LA VISUALISATION ===\")\n",
    "    #        print(f\"Nouvelle p√©riode MA: {MA_PERIOD}, FFT Pics: {TOP_FREQUENCIES}\")\n",
    "    #        print()\n",
    "    #        create_visualization()\n",
    "\n",
    "duree_slider.observe(on_slider_change, names='value')\n",
    "interval_dropdown.observe(on_slider_change, names='value')\n",
    "symbol_dropdown.observe(on_slider_change, names='value')\n",
    "end_date_picker.observe(on_slider_change, names='value')\n",
    "ma_period_slider.observe(on_slider_change, names='value')\n",
    "top_freq_slider.observe(on_slider_change, names='value')\n",
    "\n",
    "# Cr√©er des labels s√©par√©s pour un meilleur alignement\n",
    "symbol_label = Label(value='Symbole:', layout={'width': '120px'})\n",
    "duree_label = Label(value='Dur√©e (jours):', layout={'width': '120px'})\n",
    "interval_label = Label(value='Intervalle:', layout={'width': '120px'})\n",
    "end_date_label = Label(value='Date de fin:', layout={'width': '120px'})\n",
    "ma_period_label = Label(value='MA P√©riode:', layout={'width': '120px'})\n",
    "top_freq_label = Label(value='FFT Pics:', layout={'width': '120px'})\n",
    "\n",
    "# Supprimer les descriptions des widgets pour √©viter la duplication\n",
    "symbol_dropdown.description = ''\n",
    "duree_slider.description = ''\n",
    "interval_dropdown.description = ''\n",
    "end_date_picker.description = ''\n",
    "ma_period_slider.description = ''\n",
    "top_freq_slider.description = ''\n",
    "\n",
    "# Cr√©er une seule \"card\" pour tous les contr√¥les\n",
    "main_card = VBox([\n",
    "    # Premi√®re ligne: Symbole\n",
    "    HBox([symbol_label, symbol_dropdown], layout={'justify_content': 'flex-start'}),\n",
    "    # Deuxi√®me ligne: Dur√©e\n",
    "    HBox([duree_label, duree_slider], layout={'justify_content': 'flex-start'}),\n",
    "    # Troisi√®me ligne: Intervalle\n",
    "    HBox([interval_label, interval_dropdown], layout={'justify_content': 'flex-start'}),\n",
    "    # Quatri√®me ligne: Date de fin\n",
    "    HBox([end_date_label, end_date_picker], layout={'justify_content': 'flex-start'}),\n",
    "    # Cinqui√®me ligne: MA P√©riode\n",
    "    HBox([ma_period_label, ma_period_slider], layout={'justify_content': 'flex-start'}),\n",
    "    # Sixi√®me ligne: FFT Pics\n",
    "    HBox([top_freq_label, top_freq_slider], layout={'justify_content': 'flex-start'}),\n",
    "    # Septi√®me ligne: Boutons (s√©par√©s par un peu d'espace)\n",
    "    HBox([download_button, visualize_button], layout={'justify_content': 'flex-start', 'margin': '15px 0px 0px 0px'})\n",
    "], layout={\n",
    "    'border': '2px solid #e0e0e0',\n",
    "    'border_radius': '8px',\n",
    "    'padding': '15px',\n",
    "    'margin': '10px 0px',\n",
    "    'background_color': '#f8f9fa',\n",
    "    'width': '100%'\n",
    "})\n",
    "\n",
    "display(main_card)\n",
    "display(output_area)\n",
    "\n",
    "# Affichage initial de la configuration\n",
    "update_config_display()\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def download_binance_vision_data(symbol=SYMBOL, interval=INTERVAL, days_back=DUREE_JOURS, end_date_str=None):\n",
    "\n",
    "    # R√©solution de la date de fin\n",
    "    if end_date_str is None:\n",
    "        try:\n",
    "            end_date_str = END_DATE  # variable globale d√©finie dans la cellule de config\n",
    "        except NameError:\n",
    "            end_date_str = None\n",
    "\n",
    "    if end_date_str:\n",
    "        try:\n",
    "            end_date = datetime.strptime(end_date_str, '%Y-%m-%d')\n",
    "        except Exception:\n",
    "            print(f\"Format END_DATE invalide: {end_date_str}. Utilisation de datetime.now().\")\n",
    "            end_date = datetime.now()\n",
    "    else:\n",
    "        end_date = datetime.now()\n",
    "\n",
    "    # Calculer la date de d√©but\n",
    "    start_date = end_date - timedelta(days=days_back)\n",
    "\n",
    "    # Construire la liste des dates √† t√©l√©charger\n",
    "    dates = []\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        dates.append(current_date.strftime('%Y-%m-%d'))\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    # Cr√©ation des widgets de progression\n",
    "    progress_bar = FloatProgress(\n",
    "        value=0,\n",
    "        min=0,\n",
    "        max=len(dates),\n",
    "        bar_style='info',\n",
    "        style={'bar_color': '#00c851'},\n",
    "        orientation='horizontal'\n",
    "    )\n",
    "    \n",
    "    # status_label = HTML(value=f\"<b>Pr√©paration du t√©l√©chargement de {len(dates)} fichiers...</b>\")\n",
    "    \n",
    "    # Conteneur pour afficher la barre de progression\n",
    "    progress_widget = VBox([progress_bar])\n",
    "    display(progress_widget)\n",
    "\n",
    "    all_data = []\n",
    "    success_count = 0\n",
    "    total_periods = 0\n",
    "\n",
    "    from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "    def fetch_for_date(date_str):\n",
    "        \"\"\"T√©l√©charge et retourne un tuple (date_str, df_day or None, error_message or None, periods_count)\"\"\"\n",
    "        url = f\"https://data.binance.vision/data/spot/daily/klines/{symbol}/{interval}/{symbol}-{interval}-{date_str}.zip\"\n",
    "        try:\n",
    "            # Petite trace locale (renvoy√©e pour agr√©gation)\n",
    "            resp = requests.get(url, timeout=30)\n",
    "            if resp.status_code == 200:\n",
    "                with zipfile.ZipFile(BytesIO(resp.content)) as zip_file:\n",
    "                    csv_filename = f\"{symbol}-{interval}-{date_str}.csv\"\n",
    "                    if csv_filename in zip_file.namelist():\n",
    "                        csv_content = zip_file.read(csv_filename)\n",
    "                        df_day = pd.read_csv(BytesIO(csv_content), header=None, names=[\n",
    "                            'timestamp', 'open', 'high', 'low', 'close', 'volume',\n",
    "                            'close_time', 'quote_asset_volume', 'number_of_trades',\n",
    "                            'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'\n",
    "                        ])\n",
    "                        return (date_str, df_day, None, len(df_day))\n",
    "                    else:\n",
    "                        return (date_str, None, 'CSV not found in ZIP', 0)\n",
    "            else:\n",
    "                return (date_str, None, f'HTTP {resp.status_code}', 0)\n",
    "        except requests.exceptions.RequestException:\n",
    "            return (date_str, None, 'Network error', 0)\n",
    "        except zipfile.BadZipFile:\n",
    "            return (date_str, None, 'Bad ZIP', 0)\n",
    "        except Exception as e:\n",
    "            return (date_str, None, str(e)[:200], 0)\n",
    "\n",
    "    # Param√®tres de parall√©lisme: limiter le nombre de threads raisonnablement\n",
    "    max_workers = min(12, max(4, len(dates)))\n",
    "    completed_count = 0\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as exe:\n",
    "        future_to_date = {exe.submit(fetch_for_date, d): d for d in dates}\n",
    "        for fut in as_completed(future_to_date):\n",
    "            date_str = future_to_date[fut]\n",
    "            try:\n",
    "                d, df_day, err, periods = fut.result()\n",
    "                completed_count += 1\n",
    "                \n",
    "                # Mise √† jour de la barre de progression\n",
    "                progress_bar.value = completed_count\n",
    "                \n",
    "                if df_day is not None:\n",
    "                    # --- Normalisation des timestamps: uniformiser en microsecondes (us) ---\n",
    "                    try:\n",
    "                        # S'assurer que la colonne 'timestamp' existe et est num√©rique\n",
    "                        if 'timestamp' not in df_day.columns:\n",
    "                            # si les colonnes sont index√©es num√©riquement, la premi√®re colonne est le timestamp\n",
    "                            df_day.rename(columns={0: 'timestamp'}, inplace=True)\n",
    "                        df_day['timestamp'] = pd.to_numeric(df_day['timestamp'], errors='coerce')\n",
    "                    except Exception:\n",
    "                        pass\n",
    "\n",
    "                    try:\n",
    "                        # D√©tecter les timestamps inf√©rieurs au seuil (2025-01-01)\n",
    "                        threshold_dt = datetime(2025, 1, 1)\n",
    "                        # Seuil en millisecondes correspondant √† 2025-01-01\n",
    "                        threshold_ms = int(threshold_dt.timestamp() * 1000)\n",
    "\n",
    "                        # Heuristique: si la majorit√© des timestamps sont < threshold_ms*10, ils sont probablement en ms\n",
    "                        max_ts = pd.to_numeric(df_day['timestamp'], errors='coerce').max()\n",
    "                        if pd.notna(max_ts):\n",
    "                            # Si le maximum observ√© est inf√©rieur √† threshold_ms * 10, on suppose que les valeurs sont en ms\n",
    "                            if max_ts < threshold_ms * 10:\n",
    "                                mask_ms = pd.to_numeric(df_day['timestamp'], errors='coerce') < (threshold_ms * 10)\n",
    "                                if mask_ms.any():\n",
    "                                    df_day.loc[mask_ms, 'timestamp'] = pd.to_numeric(df_day.loc[mask_ms, 'timestamp'], errors='coerce') * 1000\n",
    "                    except Exception as e:\n",
    "                        print(f\"‚ö† Erreur lors de la normalisation des timestamps: {e}\")\n",
    "\n",
    "                    all_data.append(df_day)\n",
    "                    success_count += 1\n",
    "                    total_periods += periods\n",
    "                    \n",
    "            except Exception as e:\n",
    "                completed_count += 1\n",
    "                progress_bar.value = completed_count\n",
    "               \n",
    "    # Finalisation de la barre de progression\n",
    "    progress_bar.bar_style = 'success' if success_count > 0 else 'danger'\n",
    "   \n",
    "    # Petit d√©lai global pour rester poli si n√©cessaire\n",
    "    time.sleep(0.1)\n",
    "\n",
    "    if all_data:\n",
    "        # Combiner toutes les donn√©es\n",
    "        combined_df = pd.concat(all_data, ignore_index=True)\n",
    "        return combined_df.to_dict('records')\n",
    "    else:\n",
    "        print(\"Aucune donn√©e r√©cup√©r√©e via Binance Vision\")\n",
    "        return []\n",
    "\n",
    "def create_dataframe(data, symbol_name):\n",
    "    if not data:\n",
    "        print(f\"Aucune donn√©e disponible pour {symbol_name}\")\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    df = pd.DataFrame(data, columns=[\n",
    "        'timestamp', 'open', 'high', 'low', 'close', 'volume',\n",
    "        'close_time', 'quote_asset_volume', 'number_of_trades',\n",
    "        'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'\n",
    "    ])\n",
    "    \n",
    "    # Conversion des types\n",
    "    for col in ['open', 'high', 'low', 'close', 'volume']:\n",
    "        df[col] = df[col].astype(float)\n",
    "    \n",
    "    # Gestion des timestamps - Binance Vision utilise diff√©rents formats\n",
    "    timestamp_converted = False\n",
    "    \n",
    "    try:\n",
    "        # Essai avec microsecondes (format attendu apr√®s normalisation)\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='us')\n",
    "        timestamp_converted = True\n",
    "        # print(\"‚úì Timestamps convertis depuis microsecondes\")\n",
    "    except (ValueError, pd.errors.OutOfBoundsDatetime, OverflowError):\n",
    "        try:\n",
    "            # Essai avec millisecondes (fallback)\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "            timestamp_converted = True\n",
    "        except (ValueError, pd.errors.OutOfBoundsDatetime, OverflowError):\n",
    "            try:\n",
    "                # Essai avec secondes\n",
    "                df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "                timestamp_converted = True\n",
    "            except (ValueError, pd.errors.OutOfBoundsDatetime, OverflowError):\n",
    "                try:\n",
    "                    # Si les valeurs sont trop grandes, diviser par 1000000 (microsecondes vers secondes)\n",
    "                    df['timestamp'] = pd.to_datetime(df['timestamp'] / 1000000, unit='s')\n",
    "                    timestamp_converted = True\n",
    "                except (ValueError, pd.errors.OutOfBoundsDatetime, OverflowError):\n",
    "                    print(\"‚úó Impossible de convertir les timestamps\")\n",
    "\n",
    "    if not timestamp_converted:\n",
    "        print(f\"‚úó Erreur: Impossible de traiter les timestamps pour {symbol_name}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # V√©rifier la plausibilit√© des dates\n",
    "    min_date = df['timestamp'].min()\n",
    "    max_date = df['timestamp'].max()\n",
    "    \n",
    "    if min_date.year < 2009 or max_date.year > 2030:\n",
    "        print(f\"‚ö† Dates suspectes d√©tect√©es: {min_date} √† {max_date}\")\n",
    "    \n",
    "    df.set_index('timestamp', inplace=True)\n",
    "    \n",
    "    # Supprimer les doublons et trier\n",
    "    df = df[~df.index.duplicated(keep='first')].sort_index()\n",
    "    \n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
